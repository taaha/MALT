# _MALT: Mechanistic Ablation of Lossy Translation_ in LLMs for low resource languages

To be published soon. 

Code is borrowed from implementation of [Refusal in Language Models Is Mediated by a Single Direction](https://arxiv.org/abs/2406.11717) paper. Thanks a lot to these authors for their efforts.

## Input Dataset
[link](https://huggingface.co/datasets/darthPanda/ur_en_questions)

Dataset can be found in csv format in folder `dataset/dataset_CSV`

## Viewing Results
Results can be viewed in the results folder.
Following columns can be found in CSV


| **Column**                       | **Description**                                                                                             |
|----------------------------------|-------------------------------------------------------------------------------------------------------------|
| **Original Instruction**         | This is the input instruction in Urdu given to MALT.                                                       |
| **Translated Instruction**       | This is the English translation of the input instruction. (not part of our methodology) |
| **Baseline Completion**          | This is the output from the original unedited LLM in Urdu.                                                 |
| **Intervention Completion**      | This is the output from the edited LLM in English after ablating translation features.                                |
| **Translated Completion (Final Output)** | This is the final output generated from MALT after translation of the intervention completion.                     |


**Translated Instruction** column is solely for understanding of English speakers and not part of our methodology or seen by MALT.

## Deployment

This code was run on following machine

    ubuntu: 22.04
    python: 3.11
    cuda: 12.4.1
    pytorch: 2.4.0
    GPU: RTX-A4000


## Reproducing the results

download or clone this repository.

This code uses Gemma-2-2b and Llama-3.2-3b which both are gated. To run this project, you will need to add your huggingface token to .env file.

    HUGGINGFACE_TOKEN="YOUR HUGGINGFACE TOKEN"

Install the dependencies using pip

    pip install -r requirements.txt

Refusal directions are already extracted amd in directions folder. Optionally they can be generated by

    chmod +x find_translation_dir.sh
    ./find_translation_dir.sh

Outputs can be generated by

    chmod +x generate_outputs.sh
    ./generate_outputs.sh
